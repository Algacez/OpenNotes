#  å‘é‡æ±‚å’Œ

## âš  é¢˜ç›®æè¿°
æœ¬é¢˜è¦æ±‚ä½ åœ¨**GPU**ä¸Šå®ç°ä¸€ä¸ªé€å…ƒç´ ç›¸åŠ çš„å‘é‡æ±‚å’Œï¼Œè§„å®šæ¯ä¸ªå…ƒç´ ä¸º32ä½æµ®ç‚¹æ•°ã€‚

ç¨‹åºåº”å½“æ¥æ”¶ä¸¤ä¸ªå‘é‡ä½œä¸ºè¾“å…¥ï¼Œä¸€ä¸ªå‘é‡ä½œä¸ºè¾“å‡ºã€‚

ä½ éœ€è¦è¡¥å…¨ä¸‹åˆ—ä»£ç ä¸­çš„`vector_add`å‡½æ•°æ¥å®ç°å‘é‡æ±‚å’Œï¼š

```C
#include <cuda_runtime.h>

__global__ void vector_add(const float* A, const float* B, float* C, int N) {

}

// A, B, C are device pointers (i.e. pointers to memory on the GPU)
extern "C" void solve(const float* A, const float* B, float* C, int N) {
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;

    vector_add<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);
    cudaDeviceSynchronize();
}
```

**ç¤ºä¾‹ï¼š**

è¾“å…¥å‘é‡ Aï¼š
$$
\begin{bmatrix}
30.0 && 31.0 && 60.0 && 70.0 \\
\end{bmatrix}
$$
è¾“å…¥å‘é‡Bï¼š
$$
\begin{bmatrix}
20.0 && 45.0 && 12.0 && 31.9 \\
\end{bmatrix}
$$
è¾“å‡ºå‘é‡Cï¼š
$$
\begin{bmatrix}
50.0 && 76.0 && 72.0 && 101.9 \\
\end{bmatrix}
$$
**æ•°æ®é™åˆ¶**ï¼š

- è¾“å…¥å‘é‡Aå’Œå‘é‡Bæœ‰ç›¸åŒçš„é•¿åº¦
- å‘é‡é•¿åº¦ $N \leq 100,000,000$

**è¦æ±‚ï¼š**

- ä¸èƒ½ä½¿ç”¨å¤–éƒ¨åº“
- ä¸å…è®¸ä¿®æ”¹`Solve`å‡½æ•°
- ç¨‹åºçš„è¾“å‡ºåº”å½“å­˜å‚¨åœ¨å‘é‡**C**ä¸­

**tipsï¼š**
- æ¨èè‡ªå·±æ„å»ºæ•°æ®é›†ï¼Œåœ¨æœ¬åœ°åˆæ­¥æµ‹è¯•ç¨‹åºçš„æ­£ç¡®æ€§åå†æäº¤ã€‚


## ğŸ¥¨åˆ†æ•°åˆ†å¸ƒ

- å¦‚æœä½ èƒ½æˆåŠŸå†™å‡ºæ­£ç¡®çš„ç¨‹åºï¼Œè·å¾— 100% çš„åˆ†æ•°ã€‚
- å°è¯•åˆ†æä½ å½“å‰ç¨‹åºçš„æ€§èƒ½ï¼Œè¯•å›¾ä¼˜åŒ–ï¼Œå°†ä¼˜åŒ–çš„è¿‡ç¨‹æ€»ç»“æˆæ–‡æ¡£æäº¤ï¼Œæœ€é«˜èƒ½è·å¾—é¢å¤–çš„20%åˆ†æ•°ã€‚



---



## å‡½æ•°éƒ¨åˆ†
```
__global__ void vector_add(const float* A, const float* B, float* C, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        C[idx] = A[idx] + B[idx];
    }
}
```

## ä¼˜åŒ–
ä½¿ç”¨CUDAæµï¼Œåˆ©ç”¨ `cudaMemcpyAsync` å®ç°è®¡ç®—å’Œæ•°æ®ä¼ è¾“çš„é‡å ï¼Œæå‡ç¨‹åºæ€»ååé‡ã€‚
### å®Œæ•´ç¨‹åº
```
#include <cuda_runtime.h>
#include <iostream>
#include <vector>

__global__ void vector_add(const float* A, const float* B, float* C, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        C[idx] = A[idx] + B[idx];
    }
}

extern "C" void solve(const float* A, const float* B, float* C, int N, cudaStream_t stream) {
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;

    // åœ¨ç»™å®š stream ä¸­å¯åŠ¨ kernel
    vector_add<<<blocksPerGrid, threadsPerBlock, 0, stream>>>(A, B, C, N);
}

int main() {
    // ä¸»æœºæ•°æ®
    std::vector<float> h_A = {30.0, 31.0, 60.0, 70.0};
    std::vector<float> h_B = {20.0, 45.0, 12.0, 31.9};
    int N = h_A.size();

    // è®¾å¤‡å†…å­˜
    float *d_A, *d_B, *d_C;
    cudaMalloc(&d_A, N * sizeof(float));
    cudaMalloc(&d_B, N * sizeof(float));
    cudaMalloc(&d_C, N * sizeof(float));

    // åˆ›å»ºæµ
    cudaStream_t stream;
    cudaStreamCreate(&stream);

    // å¼‚æ­¥æ‹·è´åˆ°è®¾å¤‡
    cudaMemcpyAsync(d_A, h_A.data(), N * sizeof(float), cudaMemcpyHostToDevice, stream);
    cudaMemcpyAsync(d_B, h_B.data(), N * sizeof(float), cudaMemcpyHostToDevice, stream);

    // åœ¨æµä¸­æ‰§è¡Œè®¡ç®—
    solve(d_A, d_B, d_C, N, stream);

    // å¼‚æ­¥æ‹·è´ç»“æœå›ä¸»æœº
    std::vector<float> h_C(N);
    cudaMemcpyAsync(h_C.data(), d_C, N * sizeof(float), cudaMemcpyDeviceToHost, stream);

    // ç­‰å¾…æµä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    cudaStreamSynchronize(stream);

    // æ‰“å°ç»“æœ
    std::cout << "ç»“æœå‘é‡: ";
    for (float val : h_C) {
        std::cout << val << " ";
    }
    std::cout << std::endl;

    // é‡Šæ”¾èµ„æº
    cudaStreamDestroy(stream);
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);

    return 0;
}
```
